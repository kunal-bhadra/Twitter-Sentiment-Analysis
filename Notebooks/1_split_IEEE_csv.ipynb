{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdFRBUO7elt6"
      },
      "source": [
        "Here, we are splitting an IEEE CSV to get Tweet IDs. After that, we will hydrate them with the *Hydrator* app into a JSON file. Then inside the app, we will convert it into a CSV file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Displaying an example file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YdkbFeMME6Vf"
      },
      "outputs": [],
      "source": [
        "file1 = \"C:\\Data Science\\Jupyter_Workspace\\Twitter_Sentiment\\Data\\March25_20\\Raw Info\\corona_tweets_08.csv\"\n",
        "csv1 = pd.read_csv(file1, header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Xu2Pv6Mn51",
        "outputId": "da37c910-7293-4974-cc48-0a46a78b5b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     0         1\n",
            "0  1242693296553693186  0.075000\n",
            "1  1242693296750833664  0.000000\n",
            "2  1242693297178578944  0.000000\n",
            "3  1242693297296080896  0.033333\n",
            "4  1242693297509773314  0.000000\n",
            "5  1242693297551917056 -0.250000\n",
            "6  1242693297925017601  0.000000\n",
            "7  1242693299196002304  0.000000\n",
            "8  1242693299422367745 -0.250000\n",
            "9  1242693299510693888  0.000000\n",
            "(1272592, 2)\n"
          ]
        }
      ],
      "source": [
        "print(csv1.head(10))\n",
        "print(csv1.shape)\n",
        "#here, the Tweet IDs are the left column while the sentiment scores are the right column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline to split the Data from IEEE files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_id_score(ieee_path, id_path, score_path):\n",
        "    #reading in IEEE file\n",
        "    ieee_csv = pd.read_csv(ieee_path, header=None)\n",
        "    \n",
        "    #storing the values separately\n",
        "    ids_csv = ieee_csv.iloc[:,0] #IDs are in first column\n",
        "    scores_csv = ieee_csv.iloc[:,1] #baseline TextBlob scores are in second column\n",
        "    \n",
        "    #exporting to separate CSVs\n",
        "    ids_csv.to_csv(id_path, index=False)\n",
        "    scores_csv.to_csv(score_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using the Pipeline to split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#March 27, 2020\n",
        "ieee_mar27_20_path = \"C:\\Data Science\\Jupyter_Workspace\\Twitter_Sentiment\\Data\\March27_20\\Raw Info\\\\corona_tweets_10.csv\"\n",
        "ids_mar27_20_path = \"C:\\Data Science\\Jupyter_Workspace\\Twitter_Sentiment\\Data\\March27_20\\Raw Info\\\\ids_mar27_20.csv\"\n",
        "scores_mar27_20_path = \"C:\\Data Science\\Jupyter_Workspace\\Twitter_Sentiment\\Data\\March27_20\\Raw Info\\\\scores_mar27_20.csv\"\n",
        "#splitting\n",
        "split_id_score(ieee_mar27_20_path, ids_mar27_20_path, scores_mar27_20_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bulk Splitting the IEEE Files to extract Tweet ID files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "ieee_path = \"C:\\Data Science\\Jupyter_Workspace\\Twitter_Sentiment\\Data\\IEEE CSVs\"\n",
        "id_path = \"C:\\Data Science\\Jupyter_Workspace\\Twitter_Sentiment\\Data\\IDs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bulk_split(ieee_path, id_path):\n",
        "    import os\n",
        "    import re\n",
        "    import pandas as pd\n",
        "    directory = os.fsencode(ieee_path)\n",
        "        \n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        file_path = ieee_path + '//' + filename\n",
        "        ieee_csv = pd.read_csv(file_path, header=None)\n",
        "        ids_csv = ieee_csv.iloc[:,0] #IDs are in first column\n",
        "        id_str = re.findall(\"(\\w+).csv\", filename)\n",
        "        actual_id_path = id_path + '\\\\' + (str)(id_str[0]) + '_ID' + '.csv'\n",
        "        ids_csv.to_csv(actual_id_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "bulk_split(ieee_path, id_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Combine_Multiple_CSVs",
      "provenance": []
    },
    "interpreter": {
      "hash": "d65ed39dd581ebcf9df35782933087a7829422d005b2b32c58247ec95bc3be21"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
